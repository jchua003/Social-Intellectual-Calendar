name: Hybrid Events Processing

on:
  schedule:
    # Run daily at 3 AM EST (8 AM UTC)
    - cron: '0 8 * * *'
  workflow_dispatch:
    inputs:
      scrape_mode:
        description: 'Scraping mode'
        required: true
        default: 'hybrid'
        type: choice
        options:
          - 'csv_only'      # Only process CSV files
          - 'scrape_only'   # Only run web scrapers
          - 'hybrid'        # Both CSV and web scraping

jobs:
  update-events:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('scraper/requirements.txt') }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          
          # Install basic dependencies
          pip install python-dateutil requests beautifulsoup4 lxml
          
          # Install Selenium dependencies if not CSV only
          if [ "${{ github.event.inputs.scrape_mode || 'hybrid' }}" != "csv_only" ]; then
            pip install selenium undetected-chromedriver
            
            # Install Chrome for GitHub Actions
            sudo apt-get update
            sudo apt-get install -y google-chrome-stable
            
            # ChromeDriver is handled by undetected-chromedriver
          fi
      
      - name: Debug environment
        run: |
          echo "Current directory: $(pwd)"
          echo "Scraper directory contents:"
          ls -la scraper/
          echo "CSV data directory:"
          ls -la scraper/csv_data/ || echo "No csv_data directory"
      
      - name: Process events
        id: process
        run: |
          cd scraper
          MODE="${{ github.event.inputs.scrape_mode || 'hybrid' }}"
          
          echo "Running in $MODE mode"
          
          if [ "$MODE" = "csv_only" ] || [ "$MODE" = "hybrid" ]; then
            echo "=== Processing CSV files ==="
            python csv_to_events.py || {
              echo "CSV processing failed!"
              exit 1
            }
          fi
          
          if [ "$MODE" = "scrape_only" ] || [ "$MODE" = "hybrid" ]; then
            echo -e "\n=== Running web scrapers ==="
            
            # First try the targeted scraper
            if [ -f "targeted_scraper.py" ]; then
              echo "Running targeted scraper..."
              python -c "
from targeted_scraper import TargetedMuseumScraper
scraper = TargetedMuseumScraper()
events = scraper.scrape_all_museums()
print(f'Targeted scraper found {len(events)} events')
"
            fi
            
            # Run hybrid scraper if in hybrid mode
            if [ "$MODE" = "hybrid" ] && [ -f "hybrid_scraper.py" ]; then
              echo "Running hybrid scraper..."
              python hybrid_scraper.py || echo "Some scrapers failed, but continuing..."
            fi
          fi
          
          # Count final events
          if [ -f "../data/events.json" ]; then
            EVENT_COUNT=$(python -c "
import json
with open('../data/events.json') as f:
    data = json.load(f)
    total = len(data.get('events', []))
    print(total)
")
            echo "event_count=$EVENT_COUNT" >> $GITHUB_OUTPUT
            
            # Get source breakdown if available
            python -c "
import json
with open('../data/events.json') as f:
    data = json.load(f)
    if 'sources' in data:
        print(f\"CSV events: {data['sources'].get('csv_count', 0)}\")
        print(f\"Scraped events: {data['sources'].get('scraped_count', 0)}\")
" || true
          else
            echo "No events.json file created!"
            echo "event_count=0" >> $GITHUB_OUTPUT
          fi
      
      - name: Commit and push
        if: steps.process.outputs.event_count != '0'
        run: |
          git config user.email "action@github.com"
          git config user.name "GitHub Action"
          
          git add data/events.json
          
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            EVENT_COUNT="${{ steps.process.outputs.event_count }}"
            MODE="${{ github.event.inputs.scrape_mode || 'hybrid' }}"
            git commit -m "Update events - $EVENT_COUNT total events ($MODE mode)"
            git push
          fi
      
      - name: Create summary
        if: always()
        run: |
          echo "## Events Processing Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Mode**: ${{ github.event.inputs.scrape_mode || 'hybrid' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Total events**: ${{ steps.process.outputs.event_count || '0' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Run time**: $(date)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Show which museums succeeded/failed
          if [ -f "scraper/scraper_log.txt" ]; then
            echo "### Scraping Results" >> $GITHUB_STEP_SUMMARY
            cat scraper/scraper_log.txt >> $GITHUB_STEP_SUMMARY
          fi
